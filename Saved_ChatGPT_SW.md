**You:**

you are an expert of technical BA, and please recommend a solution of use ChatGPT to write user stories

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Certainly! Using ChatGPT to write user stories can be beneficial for a technical Business Analyst (BA). Here's a recommended solution:


- **Define the Purpose**: Start by clearly articulating the purpose or goal of your business analyst project. Understanding what problem or opportunity you're addressing is crucial[[3](https://www.quora.com/As-a-business-analyst-when-writing-user-stories-how-detailed-should-the-acceptance-criteria-be)].
- **Use Specific Prompts**: Execute a specific command to ChatGPT asking it to write the most important aspects of the user story. For instance: "ChatGPT, please write the most important features of an e-commerce checkout process"[[1](https://www.linkedin.com/pulse/best-chatgpt-prompts-for-business-development-manuel-pistner)].
- **Clarify Acceptance Criteria**: After generating the user story, ask ChatGPT to detail the acceptance criteria. Ensure that the acceptance criteria are clear and meaningful to your entire project team[[4](https://www.businessanalysisexperts.com/user-stories-guide-writing-requirements/)].
- **Refine and Review**: Continuously refine the user stories by discussing them with stakeholders. ChatGPT can assist by suggesting improvements based on feedback.
- **Leverage ChatGPT for Other BA Tasks**: Beyond user stories, you can use ChatGPT as an assistant for other business analysis tasks such as writing use cases, generating Gherkin Given-When-Then scenarios, and more[[2](https://thebrazilianba.com/2023/01/24/chat-gpt-as-a-tool-for-business-analysis/), [5](https://www.bestpromptsdb.com/business-analysis/)].
- **Stay Updated with Prompts**: Periodically check resources that provide useful ChatGPT prompts tailored for business analysts. This ensures you're leveraging the tool to its maximum potential[[5](https://www.bestpromptsdb.com/business-analysis/)].

## üåê Sources

- [linkedin.com - BEST CHATGPT PROMPTS FOR BUSINESS ...](https://www.linkedin.com/pulse/best-chatgpt-prompts-for-business-development-manuel-pistner)
- [thebrazilianba.com - Chat GPT as a tool for business analysis](https://thebrazilianba.com/2023/01/24/chat-gpt-as-a-tool-for-business-analysis/)
- [quora.com - As a business analyst, when writing user stories, how ...](https://www.quora.com/As-a-business-analyst-when-writing-user-stories-how-detailed-should-the-acceptance-criteria-be)
- [businessanalysisexperts.com - The Everything User Story Guide: Tips and Tricks for ...](https://www.businessanalysisexperts.com/user-stories-guide-writing-requirements/)
- [bestpromptsdb.com - 46 Best ChatGPT Prompts for Business Analysts](https://www.bestpromptsdb.com/business-analysis/)
- [scribbr.com - Using ChatGPT for Assignments | Tips & Examples](https://www.scribbr.com/ai-tools/chatgpt-assignments/)



------------------

**You:**

for above answer , please give me a set of sample

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Certainly! Let's provide a sample set based on the previous solution, using ChatGPT to write user stories:

**Scenario**: A user wants to purchase a product from an e-commerce website.


- **Define the Purpose**:
   - Problem Statement: Users find the existing checkout process lengthy and non-intuitive.
   - Opportunity: Streamline the checkout process to enhance user experience and increase sales conversions.
- **ChatGPT User Story Prompt**:
   - "ChatGPT, please write the most important features of an e-commerce checkout process."
**Sample ChatGPT Output**:
   - "As an online shopper, I want a simplified checkout process so that I can quickly purchase my desired products."
- **Clarify Acceptance Criteria with ChatGPT**:
   - "ChatGPT, provide acceptance criteria for a simplified e-commerce checkout process."
**Sample ChatGPT Output**:
   - "1. Users should be able to check out in a maximum of 3 steps."
   - "2. Users should have the option to use multiple payment methods."
   - "3. There should be clear error messages for any checkout issues."
   - "4. Users should receive a confirmation email upon successful purchase."
- **Refinement**:
   - Feedback from Stakeholder: "Can we include an option for users to apply discount codes?"
   - ChatGPT Suggestion: "As an online shopper, I want to apply a discount code during checkout to avail discounts on my purchase."
- **Other BA Task with ChatGPT**:
   - "ChatGPT, suggest a Gherkin Given-When-Then scenario for the discount code feature."
**Sample ChatGPT Output**:
   - "Given I am on the checkout page,"
   - "When I enter a valid discount code,"
   - "Then the corresponding discount should be applied to my total bill."

This sample set demonstrates how ChatGPT can be integrated into the process of user story writing and refinement in the context of a technical Business Analyst's tasks[[1](https://medium.com/nerd-for-tech/streamline-user-story-writing-with-chatgpt-84f2202fa95f), [2](https://clickup.com/templates/ai-prompts/user-stories), [3](https://cookup.ai/u/write-acceptance-criteria-for-a-user-story-ywppyolm/), [4](https://www.linkedin.com/pulse/streamline-user-story-writing-chatgpt-new-age-tatevik-harutyunyan)].

## üåê Sources

- [medium.com - Streamline User Story Writing with ChatGPT - Medium](https://medium.com/nerd-for-tech/streamline-user-story-writing-with-chatgpt-84f2202fa95f)
- [clickup.com - ChatGPT Prompts For User Stories | Template by ClickUp‚Ñ¢](https://clickup.com/templates/ai-prompts/user-stories)
- [cookup.ai - Write acceptance criteria for a user story using ChatGPT](https://cookup.ai/u/write-acceptance-criteria-for-a-user-story-ywppyolm/)
- [linkedin.com - Streamline User Story Writing with ChatGPT: A New Age ...](https://www.linkedin.com/pulse/streamline-user-story-writing-chatgpt-new-age-tatevik-harutyunyan)
- [research.aimultiple.com - 50 ChatGPT Use Cases in 2023](https://research.aimultiple.com/chatgpt-use-cases/)
- [linkedin.com - Prompt Engineering User Stories](https://www.linkedin.com/pulse/prompt-engineering-high-quality-agile-user-stories-chatgpt-naydenov)



------------------

**You:**

I study how to use ChatGPT or LLM in software engineering, especially the usage of  ChatGPT or LLM during the different phases of SDLC. please help to collect the good paper or document for this area

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Certainly! Here's a collection of articles and papers that delve into the use of ChatGPT or Large Language Models (LLMs) in software engineering, specifically their integration within the Software Development Life Cycle (SDLC):


- **Software Development Life Cycle**: This article explores the various phases of SDLC, which could provide you with a foundational understanding of where LLMs like ChatGPT could be integrated[[1](https://medium.com/tech-talk-with-chatgpt/software-development-life-cycle-1e367685aac0)].
- **Application of Large Language Models in Software**: This blog post delves into the implications of incorporating LLMs into software-reliant systems. It discusses the potential impacts and changes that could be brought about by using models like ChatGPT[[2](https://insights.sei.cmu.edu/blog/application-of-large-language-models-llms-in-software-engineering-overblown-hype-or-disruptive-change/)].
- **Impact of Generative AI on the Software Development Life Cycle**: This paper specifically addresses how Agile and other project management methodologies could evolve by integrating generative AI, like ChatGPT, into various stages of the SDLC[[3](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4536700)].
- **How to Use ChatGPT for Software Development**: This resource elaborates on how ChatGPT can be utilized to identify bugs in the codebase and highlights its benefits at various stages in the SDLC[[4](https://kms-technology.com/emerging-technologies/ai/chatgpt-software-development.html)].
- **Impact of Generative AI on the Software Development Life Cycle**: Another research paper that proposes a new SDLC model based on the integration of generative AI tools, like ChatGPT[[5](https://www.researchgate.net/publication/373012726_IMPACT_OF_GENERATIVE_AI_ON_THE_SOFTWARE_DEVELOPMENT_LIFE_CYCLE_SDLC)].
- **Large Language Models for Software Engineering**: This paper categorizes LLMs used for software engineering tasks and provides a summary of the trends and usages of different LLM categories within the software engineering domain[[6](https://arxiv.org/pdf/2308.10620)].

You may want to go through these resources in detail to gain a deeper understanding of how ChatGPT and other LLMs can be effectively used throughout the SDLC.

## üåê Sources

- [medium.com - Software Development Life Cycle. Exploring phases ...](https://medium.com/tech-talk-with-chatgpt/software-development-life-cycle-1e367685aac0)
- [insights.sei.cmu.edu - Application of Large Language Models (LLMs) in Software ...](https://insights.sei.cmu.edu/blog/application-of-large-language-models-llms-in-software-engineering-overblown-hype-or-disruptive-change/)
- [papers.ssrn.com - Impact of Generative AI on the Software Development ...](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4536700)
- [kms-technology.com - How to Use ChatGPT for Software Development](https://kms-technology.com/emerging-technologies/ai/chatgpt-software-development.html)
- [researchgate.net - impact of generative ai on the software development life ...](https://www.researchgate.net/publication/373012726_IMPACT_OF_GENERATIVE_AI_ON_THE_SOFTWARE_DEVELOPMENT_LIFE_CYCLE_SDLC)
- [arxiv.org - Large Language Models for Software Engineering](https://arxiv.org/pdf/2308.10620)



------------------

**You:**

please also help to collect any open-source solution that uses ChatGPT or LLM for software engineering or use in different phases in SDLC.   it can be an open-source for a particular phase (such as  assistant Testing) , or be an open-source for multiple phases  or be an open-source for  agile planing

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Based on the provided search results, there doesn't appear to be direct information about specific open-source solutions that utilize ChatGPT or other Large Language Models (LLMs) for software engineering or various phases in the SDLC. However, based on the general knowledge about ChatGPT's applications in software engineering:


- **Assistant for Coding**: ChatGPT and other LLMs can potentially assist in coding tasks by offering code suggestions, identifying bugs, and providing explanations for specific code functions. While specific open-source tools aren't listed, integrating ChatGPT into Integrated Development Environments (IDEs) could be an innovative approach for developers[[1](https://medium.com/mlearning-ai/generative-ai-in-software-development-3e90e466eb91)][[6](https://www.infoworld.com/article/3689172/chatgpt-and-software-development.html)].
- **Software Testing Assistants**: LLMs could be used to create testing scenarios based on software requirements, making the testing phase more comprehensive and efficient.
- **Agile Planning and Documentation**: ChatGPT can be a valuable tool in Agile environments, aiding in the generation of user stories, sprint planning, and even retrospective analysis. It can potentially automate some aspects of documentation, ensuring clear and concise communication among team members.
- **Ethical Analysis**: ChatGPT and LLMs could play a role in examining the ethical aspects of software engineering research, which could be incorporated into the requirements gathering and design phases of SDLC[[4](https://www.researchgate.net/publication/371180021_Ethical_Aspects_of_ChatGPT_in_Software_Engineering_Research)].

To find specific open-source solutions, you might want to look into GitHub or other repositories that focus on the integration of ChatGPT or LLMs in software development tools or platforms.

## üåê Sources

- [medium.com - Generative AI in Software Development | by Xin Cheng](https://medium.com/mlearning-ai/generative-ai-in-software-development-3e90e466eb91)
- [insights.sei.cmu.edu - Application of Large Language Models (LLMs) in Software ...](https://insights.sei.cmu.edu/blog/application-of-large-language-models-llms-in-software-engineering-overblown-hype-or-disruptive-change/)
- [arxiv.org - Communicative Agents for Software Development](https://arxiv.org/pdf/2307.07924)
- [researchgate.net - (PDF) Ethical Aspects of ChatGPT in Software Engineering ...](https://www.researchgate.net/publication/371180021_Ethical_Aspects_of_ChatGPT_in_Software_Engineering_Research)
- [vegavid.com - Software development: Types, Tools, Methodologies and ...](https://vegavid.com/blog/software-development-types-tools-methodologies-design/)
- [infoworld.com - ChatGPT and software development](https://www.infoworld.com/article/3689172/chatgpt-and-software-development.html)



------------------

**You:**

please help for collect from GIthub?

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Certainly! Here's a collection of GitHub repositories and resources related to ChatGPT and Large Language Models (LLMs) for software engineering and different phases of the SDLC:


- **awesome-ChatGPT-repositories**: A curated list of resources dedicated to open-source GitHub repositories related to ChatGPT[[1](https://github.com/taishi-i/awesome-ChatGPT-repositories)].
- **awesome-totally-open-chatgpt**: This is a list of open alternatives to ChatGPT. It could be helpful if you're looking for open-source projects that offer similar functionalities to ChatGPT but aren't directly affiliated with OpenAI[[2](https://github.com/nichtdax/awesome-totally-open-chatgpt)].
- **Awesome-LLM**: A curated list showcasing Large Language Models (LLMs) that have made significant impacts in the AI community. This repository lists papers and resources about LLMs, which can be beneficial for understanding the advancements in this domain[[3](https://github.com/Hannibal046/Awesome-LLM)].
- **chat-gpt GitHub Topics**: This is a project that provides a FastAPI wrapper for interacting with Google Bard, a conversational AI by Google. It can be a helpful tool for developers wanting to integrate ChatGPT-like functionalities into their applications[[4](https://github.com/topics/chat-gpt)].
- **awesome-chatgpt**: A curated list of ChatGPT and OpenAI software. This repository includes documentation, examples, guides, prompt engineering resources, and more. It's a valuable resource for developers and researchers working with ChatGPT[[5](https://github.com/korchasa/awesome-chatgpt)].
- **chatgpt GitHub Topics**: General information on ChatGPT, highlighting its launch by OpenAI in November 2022, and its underlying architecture based on GPT-3[[6](https://github.com/topics/chatgpt)].

You can explore these repositories for more detailed information and see if any of them fit your specific needs or interests.

## üåê Sources

- [github.com - awesome-ChatGPT-repositories](https://github.com/taishi-i/awesome-ChatGPT-repositories)
- [github.com - nichtdax/awesome-totally-open-chatgpt](https://github.com/nichtdax/awesome-totally-open-chatgpt)
- [github.com - Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)
- [github.com - chat-gpt ¬∑ GitHub Topics](https://github.com/topics/chat-gpt)
- [github.com - korchasa/awesome-chatgpt](https://github.com/korchasa/awesome-chatgpt)
- [github.com - chatgpt ¬∑ GitHub Topics](https://github.com/topics/chatgpt)



------------------

**You:**

please collect or search open-source solutions in GitHub for technical business analysis which include gather  User Requirement , write User stories

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Certainly! Based on the provided search results, here are some GitHub repositories and topics related to technical business analysis, including gathering user requirements and writing user stories:


- **user-story-best-practice**: This repository provides guidance on how to write user stories effectively. User stories offer a simplified description of a requirement and are further divided into individual tasks that together form the complete story[[1](https://github.com/awkale/user-story-best-practice)].
- **requirement-specifications GitHub Topics**: This topic on GitHub is dedicated to projects that focus on requirement specifications. The mentioned example contains documentation using BPMN, User Stories, BDD, and other tools to help address developer challenges[[3](https://github.com/topics/requirement-specifications)].
- **business-analysis GitHub Topics**: This topic is geared towards software development practice labs that help individuals understand and master software development processes. This could potentially provide resources or repositories related to business analysis tasks such as gathering requirements[[4](https://github.com/topics/business-analysis)].
- **requirements-engineering GitHub Topics**: This topic encompasses a wide range of projects related to requirements engineering. For instance, there is a Software Requirement Specification (IEEE Standard No. 830) Template in Farsi. This indicates that there could be other relevant templates or tools in this topic that can help with gathering user requirements and detailing software specifications[[5](https://github.com/topics/requirements-engineering?o=desc&s=updated), [6](https://github.com/topics/requirements-engineering)].

To dive deeper into each resource, you can explore the linked repositories and topics. By doing so, you might find specific tools or templates that perfectly suit your business analysis needs.

## üåê Sources

- [github.com - GitHub - awkale/user-story-best-practice: How to write ...](https://github.com/awkale/user-story-best-practice)
- [github.com - user-story-best-practice/README.md at master](https://github.com/awkale/user-story-best-practice/blob/master/README.md)
- [github.com - requirement-specifications ¬∑ GitHub Topics](https://github.com/topics/requirement-specifications)
- [github.com - business-analysis ¬∑ GitHub Topics](https://github.com/topics/business-analysis)
- [github.com - requirements-engineering ¬∑ GitHub Topics (sorted by update)](https://github.com/topics/requirements-engineering?o=desc&s=updated)
- [github.com - requirements-engineering ¬∑ GitHub Topics](https://github.com/topics/requirements-engineering)



------------------

**You:**

there is open source https://github.com/pythagora-io/gpt-pilot, please read it and generate  a document to describe gpt-pilot each modules in Chinese

------------------

**ChatGPT:**

## üóíÔ∏è Answer
**GPT Pilot Ê®°ÂùóÊèèËø∞ÊñáÊ°£**

GPT Pilot ÊòØ‰∏Ä‰∏™ÂºÄÂèëÂ∑•ÂÖ∑ÔºåÊó®Âú®Â∏ÆÂä©ÂºÄÂèëËÄÖÊõ¥Âø´Âú∞ÊûÑÂª∫Â∫îÁî®„ÄÇ‰ª•‰∏ãÊòØÊ†πÊçÆÊèê‰æõÁöÑÊêúÁ¥¢ÁªìÊûúÂØπGPT PilotÁöÑÊ®°ÂùóËøõË°åÁöÑÊèèËø∞Ôºö


- **Â∫îÁî®ÊûÑÂª∫**: GPT Pilot ÂèØ‰ª•Â∏ÆÂä©ÂºÄÂèëËÄÖÊûÑÂª∫Â∫îÁî®ÔºåÊèêÈ´òÁ∫¶20ÂÄçÁöÑÂºÄÂèëÊïàÁéá„ÄÇÂΩì‰Ω†Á°ÆÂÆöË¶ÅÂª∫Á´ãÁöÑÂ∫îÁî®Á±ªÂûãÂêéÔºåGPT Pilot ‰ºöÊèêÂá∫ÊòéÁ°ÆÁöÑÈóÆÈ¢òÔºåÁÑ∂ÂêéÂàõÂª∫ËØ•‰∫ßÂìÅ[[1](https://github.com/Pythagora-io/gpt-pilot)]„ÄÇ
- **ÂõæÂΩ¢‰∫§‰∫íÁïåÈù¢**: GPT Pilot‰∏∫ChatGPT/GLMÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂõæÂΩ¢‰∫§‰∫íÁïåÈù¢ÔºåËØ•ÁïåÈù¢ÁâπÂà´‰ºòÂåñ‰∫ÜËÆ∫ÊñáÁöÑÈòÖËØª„ÄÅÊ∂¶Ëâ≤ÂíåÂÜô‰Ωú‰ΩìÈ™å[[2](https://github.com/superiorlu/AiTreasureBox/blob/main/README.zh-CN.md)]„ÄÇ
- **Ê®°ÂùóÂåñËÆæËÆ°**: ËØ•Â∑•ÂÖ∑ÂÖ∑ÊúâÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆÂíåÂáΩÊï∞Êèí‰ª∂„ÄÇÊ≠§Â§ñÔºåÂÆÉËøòÊîØÊåÅPython„ÄÅCÁ≠âÈ°πÁõÆÁöÑÂâñÊûêÂíåËá™ËØëËß£ÂäüËÉΩ[[2](https://github.com/superiorlu/AiTreasureBox/blob/main/README.zh-CN.md)]„ÄÇ
- **ÂºÄÂèëÁõëÁù£**: Èô§‰∫ÜËá™Âä®ÁºñÂÜôÂ∫îÁî®Â§ñÔºåÂºÄÂèëËÄÖËøòÂèØ‰ª•ÁõëÁù£Êï¥‰∏™ÂÆûÁé∞ËøáÁ®ãÔºåÁ°Æ‰øùÂ∫îÁî®ÁöÑË¥®ÈáèÂíåÂèØÈù†ÊÄß[[4](https://github.com/Pythagora-io/gpt-pilot/wiki)]„ÄÇ

ËØ∑Ê≥®ÊÑèÔºå‰∏äËø∞ÊèèËø∞ÊòØÂü∫‰∫éÊâÄÊèê‰æõÁöÑÊêúÁ¥¢ÁªìÊûúÂØπGPT PilotÁöÑÁÆÄË¶ÅÊ¶ÇËø∞„ÄÇ‰∏∫‰∫ÜÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£GPT PilotÁöÑÊØè‰∏™Ê®°ÂùóÔºåÂª∫ËÆÆÁõ¥Êé•ËÆøÈóÆÂÖ∂GitHub‰ªìÂ∫ìËøõË°åÊõ¥ËØ¶ÁªÜÁöÑÊé¢Á¥¢„ÄÇ

## üåê Sources

- [github.com - Pythagora-io/gpt-pilot: Dev tool that writes scalable apps ...](https://github.com/Pythagora-io/gpt-pilot)
- [github.com - AiTreasureBox/README.zh-CN.md at main](https://github.com/superiorlu/AiTreasureBox/blob/main/README.zh-CN.md)
- [blog.csdn.net - ‰∏Ä‰∫∫ËÉΩÈ°∂‰∏Ä‰∏™ÂÖ¨Âè∏ÔºåÁºñÁ®ãÁ•ûÂô®GPT PilotÔºåËØûÁîü‰∫ÜÔºÅ ËΩ¨ËΩΩ](https://blog.csdn.net/lemonbit/article/details/133896858)
- [github.com - Home ¬∑ Pythagora-io/gpt-pilot Wiki](https://github.com/Pythagora-io/gpt-pilot/wiki)



------------------

**You:**

you are an expert of software testing, and please recommend a solution of use ChatGPT/LLM to write BDD style test case, test script

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Using ChatGPT/LLM for writing BDD (Behavior Driven Development) style test cases and test scripts can revolutionize the testing process. Here's a recommended solution:


- **BDD Test Case Creation**: Start by defining the desired behavior of your application using the Given-When-Then syntax. ChatGPT can assist by generating scenarios based on high-level requirements you provide. For example, input: "Feature: User login", and ChatGPT could provide a scenario like "Given a registered user, When the user enters correct credentials, Then the user is logged in"[[1](https://www.linkedin.com/pulse/llms-gold-rush-test-automation-how-make-most-pavel-fleisher)].
- **Automated Test Plan Generation**: Provide ChatGPT with a simple prompt and some bullet points about the functionality you want to test. It can then produce an in-depth test plan complete with setup instructions and multiple test cases[[2](https://smartbear.com/blog/how-to-use-chatgpt-in-your-automated-tests/)].
- **Unit Test Automation**: ChatGPT can help in automating unit test script writing. By describing the functionality of a module or function, ChatGPT can generate the respective unit tests[[3](https://reale.medium.com/automatizing-unit-test-writing-with-chatgpt-c2fadcedab02)].
- **Simulation of User Behavior**: Generative AI techniques, such as those used by ChatGPT, can be employed to simulate user behavior and create tests based on those simulations[[4](https://www.udemy.com/course/testing-quality-engineering-gen-ai-examples-gpt-bard/)].
- **Conversion of Test Cases to Scripts**: An experienced tester can guide ChatGPT in transforming manually written 'test cases' into executable test scripts[[5](https://cubettech.com/resources/blog/before-stepping-from-manual-to-automation-testing/)].
- **Prompt Engineering**: Craft well-defined prompts for ChatGPT to refine its output. With the right prompts, ChatGPT can analyze test cases, identify issues, and suggest remedies, thereby enhancing the scope and quality of test cases[[6](https://www.zaptest.com/prompt-engineering-in-software-automation)].

Incorporating ChatGPT/LLM into your BDD test case writing process can save time, reduce errors, and improve test coverage.

## üåê Sources

- [linkedin.com - LLMs gold rush and test automation: how to make most of it?](https://www.linkedin.com/pulse/llms-gold-rush-test-automation-how-make-most-pavel-fleisher)
- [smartbear.com - How to Use ChatGPT in Your Automated Tests](https://smartbear.com/blog/how-to-use-chatgpt-in-your-automated-tests/)
- [medium.com - Automatizing Unit Test Writing with ChatGPT](https://reale.medium.com/automatizing-unit-test-writing-with-chatgpt-c2fadcedab02)
- [udemy.com - Generative AI ChatGPT and Google BARD for Software ...](https://www.udemy.com/course/testing-quality-engineering-gen-ai-examples-gpt-bard/)
- [cubettech.com - Prior Stepping From Manual To Automation Testing](https://cubettech.com/resources/blog/before-stepping-from-manual-to-automation-testing/)
- [zaptest.com - Prompt Engineering in Software Automation](https://www.zaptest.com/prompt-engineering-in-software-automation)



------------------

**You:**

please collect or search open-source solutions in GitHub for  use ChatGPT/LLM to write BDD style test case, test script

------------------

**ChatGPT:**

## üóíÔ∏è Answer
Based on the search results provided, here are some relevant open-source solutions on GitHub that relate to BDD style testing, ChatGPT/LLM, and test case generation:


- **bdd-style-testing-framework**: This framework supports Behavior Driven Development (BDD) and provides an avenue for building test cases using tools like Excel and Postman collection. While it doesn't mention ChatGPT/LLM directly, it might be adaptable to integrate ChatGPT/LLM for generating BDD style test cases[[1](https://github.com/topics/bdd-style-testing-framework)].
- **chatgpt-create-unit-tests**: This action is designed to analyze a Pull Request and add unit tests when deemed necessary or possible. There's potential here to extend or adapt this action to integrate BDD style testing with ChatGPT/LLM[[2](https://github.com/marketplace/actions/chatgpt-create-unit-tests)].
- **bdd-tests**: GitHub topics related to BDD testing indicate that there are open-source solutions that help in writing clean, testable code. This could be a resource to explore further solutions that can be integrated with ChatGPT/LLM for BDD test case writing[[3](https://github.com/topics/bdd-tests)].
- **DocsGPT**: Though not directly related to BDD style test case writing, DocsGPT streamlines the process of finding information in project documentation. It's possible that with some tweaks, ChatGPT/LLM can be utilized to extract BDD-related data from such documentation[[4](https://github.com/koji/ChatGPT-LLM-PromptEngineering_repos)].
- **test-case-generation**: An open-source test case generator script that uses techniques like Equivalence Partitioning and Boundary Value Analysis to generate test cases for given input. It doesn't mention BDD or ChatGPT/LLM directly, but could serve as a foundation for creating a more tailored solution[[5](https://github.com/topics/test-case-generation)].
- **awesome-stars**: Contains a mention of a BDD-style widget testing library. This could potentially serve as a starting point for those looking to integrate ChatGPT/LLM into their BDD widget testing workflow[[6](https://github.com/andgar2010/awesome-stars?search=1)].

While some of these repositories directly relate to BDD style testing, others may need adaptation or integration with ChatGPT/LLM to achieve the desired outcome.

## üåê Sources

- [github.com - bdd-style-testing-framework](https://github.com/topics/bdd-style-testing-framework)
- [github.com - Marketplace Actions chatgpt-create-unit-tests](https://github.com/marketplace/actions/chatgpt-create-unit-tests)
- [github.com - bdd-tests ¬∑ GitHub Topics](https://github.com/topics/bdd-tests)
- [github.com - koji/ChatGPT-LLM-PromptEngineering_repos](https://github.com/koji/ChatGPT-LLM-PromptEngineering_repos)
- [github.com - test-case-generation](https://github.com/topics/test-case-generation)
- [github.com - andgar2010/awesome-stars](https://github.com/andgar2010/awesome-stars?search=1)



------------------
## Note and Terms
 Generative AI-Assisted Software Development Life cycle (hereafter referred to as GAASD Lifecycle).
 - ** Important Document ** - [https://deliverypdf.ssrn.com/delivery.php?ID=877004071119092007100097127088064072042016062081050044108031005009081074030089093026119022001101020104098115079077000127123114126076055079016104022078006108119024024029076008000088088003093098103007097065087025027092065101079025070086100011094024117122&EXT=pdf&INDEX=TRUE).
 - ÂÅèËßÅÔºöAI Â∑•ÂÖ∑ÂÆπÊòìÂèçÊò†Âá∫Ê∫ê‰∫éÊï∞ÊçÆÊàñÊú∫Âô®Â≠¶‰π†ËøáÁ®ãÁöÑÈîôËØØÂÅáËÆæÊâÄÂØºËá¥ÁöÑÂÅèËßÅ„ÄÇ
 - ÂπªËßâÔºöAI ‰∫ßÁîüÁöÑÁªìÊûúÂíåÁªìËÆ∫ÂèØËÉΩÊòØÈîôËØØÁöÑÔºåÂÅèÁ¶ª‰∫ãÂÆûÂíåÈÄªËæë„ÄÇ
 - ‰∏ÄËá¥ÊÄßÔºöAI Â∑•ÂÖ∑Âú®Ê≤°ÊúâÈ¢ùÂ§ñÊèêÁ§∫ÁöÑÊÉÖÂÜµ‰∏ãÂæàÈöæÁîüÊàêÈïø‰∏≤ÁöÑ‰ª£Á†Å„ÄÇÂ§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºåÂ∞§ÂÖ∂ÊòØÂΩìÂ∫îÁî®Á®ãÂ∫èÂæàÂ§çÊùÇ‰∏îÊúâÂæàÂ§öÁªÑ‰ª∂Êó∂ÔºåAI ÁîüÊàêÁöÑËΩØ‰ª∂Âπ∂‰∏çÊÄªÊòØÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®„ÄÇÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåAI Â∑•ÂÖ∑ÁîüÊàêÁöÑÁªìÊûúÁÆÄÁü≠‰∏î‰∏çÂÆåÊï¥ÔºåÈúÄË¶ÅÁî®Êà∑Êèê‰æõÈ¢ùÂ§ñÁöÑ‰∏ä‰∏ãÊñá„ÄÇ
 - ‰∏çÂáÜÁ°ÆÊÄßÔºöAI Â∑•ÂÖ∑‰ΩøÁî®ÁΩëÁªúÊäìÂèñ‰ªéÂêÑÁßçÊù•Ê∫êËé∑ÂèñÊï∞ÊçÆ„ÄÇÁî±‰∫é‰∏äËø∞ÂéüÂõ†ÔºåÂ∞ΩÁÆ° AI ÊúâÂ§öÁßçÂ∫îÁî®Ôºå‰ΩÜÂÆÉ‰∏çËÉΩË¢´ËßÜ‰∏∫ÂîØ‰∏ÄÂèØÈù†ÁöÑÈÄâÊã©ÔºåÂõ†‰∏∫ÂÆÉÈúÄË¶ÅÁªèËøá‰∫∫ÊàñÊú∫Âô®ÁöÑÂÖ≥ÈîÆËØÑ‰º∞„ÄÇ
 - ÂéüÂàõÊÄßÔºöAI Â∑•ÂÖ∑‰∫ßÁîüÁöÑÁªìÊûúÂú®ÂÜÖÂÆπÂíåÁªìÊûÑ‰∏äÈÉΩÂæàÁõ∏‰ººÔºåÁîüÊàêÁöÑÁ≠îÂ§çÁº∫‰πèÂéüÂàõÊÄßÊàñÊñ∞È¢ñÊÄß„ÄÇ
 - ÊÄßËÉΩÔºöAI ÁöÑÂΩìÂâçËÉΩÂäõÊúÄÂ§öÂè™ËÉΩÊèê‰æõËæÖÂä©„ÄÇÂÆÉÁ°ÆÂÆûÂ¢ûÂº∫‰∫ÜÁî®Êà∑ÁöÑÊïàÁéáÔºå‰ΩÜËøòÊ≤°ÊúâËææÂà∞Âú®Ê≤°ÊúâÊâãÂ∑•Âπ≤È¢Ñ/ÁõëÁù£ÁöÑÊÉÖÂÜµ‰∏ãÂ∞ÜÊ¥ªÂä®‰∫§Áªô AI ÁöÑÈò∂ÊÆµ

## Tools for GAASD

First, you enter a description of an app you want to build. Then, GPT Pilot works with an LLM (currently GPT-4) to clarify the app requirements, and finally, it writes the code. It uses many AI Agents that mimic the workflow of a development agency.

After you describe the app, the Product Owner Agent breaks down the business specifications and asks you questions to clear up any unclear areas.
Then, the Software Architect Agent breaks down the technical requirements and lists the technologies that will be used to build the app.
Then, the DevOps Agent sets up the environment on the machine based on the architecture.
Then, the Tech Team Lead Agent breaks down the app development process into development tasks where each task needs to have:
Description of the task (this is the main description upon which the Developer agent will later create code)
 Description of automated tests that will need to be written so that GPT Pilot can follow TDD principles
 Description for human verification, which is basically how you, the human developer, can check if the task was successfully implemented
Finally, the Developer and the Code Monkey Agents take tasks one by one and start coding the app. The Developer breaks down each task into smaller steps, which are lower-level technical requirements that might not need to be reviewed by a human or tested with an automated test (eg. install some package).

3 Main Pillars of GPT Pilot
I call these the pillars because, since this is a research project, I wanted to be reminded of them as I work on GPT Pilot. I want to explore what‚Äôs the most that AI can do to boost developers‚Äô productivity, so all improvements I make need to lead to that goal and not create something that writes simple, fully working apps but doesn‚Äôt work at scale.

Pillar #1. Developer needs to be involved in the process of app creation
As I mentioned above, I think that we are still far away from an LLM that can just be hooked up to a CLI and work by itself to create any app by itself. Nevertheless, GPT-4 works amazingly well when writing code. I use ChatGPT all the time to speed up my development process ‚Äì especially when I need to work on some new technology or an API or if I need to create a standalone script. The first time I realized how powerful it can be was a couple of months ago when it took me 2 hours with ChatGPT to create a Redis proxy that would usually take 20 hours to develop from scratch. I wrote a whole post about that here.

So, to enable AI to generate a fully working app, we need to allow it to work closely with the developer who oversees the development process and acts as a tech team lead while AI writes most of the code. So, the developer needs to be able to change the code at any moment, and GPT Pilot needs to continue working with those changes (eg. add an API key or fix an issue if an AI gets stuck).

Here are the areas in which the developer can intervene in the development process:

After each development task is finished, the developer should review it and make sure it works as expected (this is the point where you would usually commit the latest changes)
After each failed test or command run ‚Äì it might be easier for the developer to debug something (eg. if a port on your machine is reserved but the generated app is trying to use it ‚Äì then you need to hardcode some other port)
If the AI doesn‚Äôt have access to an external service ‚Äì eg. in case you need to get and add an API key to the environment
Pillar #2. The app needs to be coded step by step
Let‚Äôs say you want to create a simple app, and you know everything you need to code and have the entire architecture in your head. Even then, you won‚Äôt code it out entirely, then run it for the first time and debug all the issues at once. Instead, you will split the app development into smaller tasks, implement one (like add routes), run it, debug, and then move on to the next task. This way, you can fix issues as they arise.

The same should be in the case when AI codes.

Like a human, it will make mistakes for sure, so for it to have an easier time debugging and for the developer to understand what is happening in the generated code, the AI shouldn‚Äôt just spit out the entire codebase at once. Instead, the app should be generated and debugged step by step just like a developer would do ‚Äì eg. setup routes, add database connection, etc.

Other code generators like Smol Developer and GPT Engineer work in a way that you write a prompt about the app you want to build, they try coding out the entire app and give you the entire codebase at once. While AI is great, it‚Äôs still far away from coding a fully working app from the first try so these tools give you the codebase that is really hard to get into and, more importantly, it‚Äôs infinitely harder to debug.

I think that if GPT Pilot creates the app step by step, both AI and the developer overseeing it will be able to fix issues more easily, and the entire development process will flow much more smoothly.

Pillar #3. GPT Pilot needs to be scalable
GPT Pilot has to be able to create large production-ready apps and not only on small apps where the entire codebase can fit into the LLM context. The problem is that all learning that an LLM has is done in-context. Maybe one day, the LLM could be fine-tuned for each specific project, but right now, it seems like that would be a very slow and redundant process.

The way that GPT Pilot addresses this issue is with context rewinding, recursive conversations, and TDD.

Context rewinding
The idea behind context rewinding is relatively simple ‚Äì for solving each development task, the context size of the first message to the LLM has to be relatively the same. For example, the context size of the first LLM message while implementing development task #5 has to be more or less the same as the first message while developing task #50. Because of this, the conversation needs to be rewound to the first message upon each task.

For GPT Pilot to solve tasks #5 and #50 in the same way, it has to understand what has been coded so far along with the business context behind all code that‚Äôs currently written so that it can create the new code only for the task that it‚Äôs currently solving and not rewrite the entire app.

I‚Äôll go deeper into this concept in the next blog post, but essentially, when GPT Pilot creates code, it makes the pseudocode for each code block that it writes, as well as descriptions for each file and folder it needs to create. So, when we need to implement each task, in a separate conversation, we show the LLM the current folder/file structure; it selects only the code that is relevant to the current task, and then, we add only that code to the original conversation that will write the actual implementation of the task.

Recursive conversations
Recursive conversations are conversations with the LLM that are set up in a way that they can be used ‚Äúrecursively‚Äù. For example, if GPT Pilot detects an error, it needs to debug it, but let‚Äôs say that another error happens during the debugging process. Then, GPT Pilot needs to stop debugging the first issue, fix the second one, and then get back to fixing the first issue. This is a crucial concept that, I believe, needs to work to make AI build large and scalable apps. It works by rewinding the context and explaining each error in the recursion separately. Once the deepest level error is fixed, we move up in the recursion and continue fixing errors until the entire recursion is completed.

TDD (Test Driven Development)
For GPT Pilot to scale the codebase, improve it, change requirements, and add new features, it needs to be able to create new code without breaking previously written code. There is no better way to do this than working with TDD methodology. For all code that GPT Pilot writes, it needs to write tests that check if the code works as intended so that whenever new changes are made, all regression tests can be run to check if anything breaks.

I‚Äôll go deeper into these three concepts in the next blog post, in which I‚Äôll break down the entire development process of GPT Pilot.

In this first blog post, I discussed the high-level overview of how GPT Pilot works. In posts 2 and 3, I show you:

How do Developer and Code Monkey agents work together to implement code (write new files or update existing ones).
How recursive conversations and context rewinding work in practice.
How can we rewind the app development process and restore it from any development step.
How are all agents structured ‚Äì As you might‚Äôve noticed, there are GPT Pilot agents, and some might be redundant right now, but I think these agents will evolve over time, so I wanted to build agents in a modular way, just like the regular code.

## GPT Pilot ‚Äì a dev tool that writes 95% of coding tasks [Part 2/3 ‚Äì Coding Workflow]
This is a second blog post in a 3-part series where I explain how my team and I created GPT Pilot ‚Äì the AI coding agent that‚Äôs designed to work at scale and build production-ready apps with a developer‚Äôs help. In part #1 of this series, I discussed the high-level overview of GPT Pilot. The idea is that AI can now do 95% of all coding that we, developers, are doing. See how I used ChatGPT to code out an entire Redis proxy in 2 hours, which would usually take 20-30 developer hours. However, an app is of no use if it doesn‚Äôt fully work or solve the user‚Äôs problem. So, until real AGI arrives, you need a developer.

So, this is how GPT Pilot came to life. It is designed to do 95% of the required coding and asks developers for reviews, such as when it becomes stuck and cannot move forward or needs something outside the app like an API key.

In this post, I walk you through the entire process GPT Pilot goes through when coding an app. I share diagrams to provide a visual representation of everything that‚Äôs going on behind the scenes in GPT Pilot. I‚Äôm a visual person, so I always create diagrams.To understand how GPT Pilot‚Äôs coding works, there are 3 concepts ‚Äì context rewinding, recursive conversations, and TDD. See my introduction where I described in them in part #1 of this series.

The GPT Pilot coding workflow contains 5 steps:

Take the next development task in line
Break down the task into development steps
Take the next development step
Fetching of currently implemented code
Write code for the current step
Run the code or a command
Test the new code changes
Debug the development step or go to the next step
Coding workflow is my favorite part of GPT Pilot so let‚Äôs dive in. Here is a diagram of how it looks like visually:

![pythagora-product-development-frame-1](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/f281e19d-f538-493b-a650-0b9c741da195)

![pythagora-product-development-frame-3-1](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/c2f4b367-06d1-4036-95cb-3a1078ab2709)


## GPT Pilot ‚Äì a dev tool that writes 95% of coding tasks [Part 2/3 ‚Äì Coding Workflow]
This is a second blog post in a 3-part series where I explain how my team and I created GPT Pilot ‚Äì the AI coding agent that‚Äôs designed to work at scale and build production-ready apps with a developer‚Äôs help. In part #1 of this series, I discussed the high-level overview of GPT Pilot. The idea is that AI can now do 95% of all coding that we, developers, are doing. See how I used ChatGPT to code out an entire Redis proxy in 2 hours, which would usually take 20-30 developer hours. However, an app is of no use if it doesn‚Äôt fully work or solve the user‚Äôs problem. So, until real AGI arrives, you need a developer.

So, this is how GPT Pilot came to life. It is designed to do 95% of the required coding and asks developers for reviews, such as when it becomes stuck and cannot move forward or needs something outside the app like an API key.

In this post, I walk you through the entire process GPT Pilot goes through when coding an app. I share diagrams to provide a visual representation of everything that‚Äôs going on behind the scenes in GPT Pilot. I‚Äôm a visual person, so I always create diagrams.To understand how GPT Pilot‚Äôs coding works, there are 3 concepts ‚Äì context rewinding, recursive conversations, and TDD. See my introduction where I described in them in part #1 of this series.

![262046521-54a8ec24-a2ea-43a6-a494-03139d4e43f5](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/b30165be-fabc-42f1-837d-07777cb2fbeb)


![gpt-pilot-coding-workfl](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/16cba26c-91c0-467a-99c2-e6fc02f454f6)


The GPT Pilot coding workflow contains 5 steps:

Take the next development task in line
Break down the task into development steps
Take the next development step
Fetching of currently implemented code
Write code for the current step
Run the code or a command
Test the new code changes
Debug the development step or go to the next step
Coding workflow is my favorite part of GPT Pilot so let‚Äôs dive in. Here is a diagram of how it looks like visually:

## 1 Task breakdown
Two important concepts will be mentioned throughout this blog post ‚Äì development tasks and development steps.

GPT Pilot works in a way that, after breaking down the specifications for developing an app, it creates development tasks that will lead to a fully working app. Development tasks are basically high-level descriptions of what needs to be done that a developer will take and start implementing. Think of them as tasks in Jira (btw, I hate Jira‚Ä¶not sure if anyone relates, but I just wanted to let it out of my system). Here is an example of a development task:

![gpt-pilot-gpt-pilot-development-task-example](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/0aaef9b3-ed10-4a75-8895-39a4139880e1)


In the diagram above, you see 3 task properties:

description: what needs to be implemented to fulfill this task
user_review_goal: how can the lead developer determine if the current task is finished ‚Äì a crucial pillar of GPT Pilot is a developer must be involved throughout the coding process so that you can ensure the development process is going as planned and understand the codebase along the way
programmatic_goal: the kind of automated test GPT Pilot should write to test if this entire development task works as expected. After a development step, GPT Pilot writes unit tests, and after a development task, it writes integration or E2E tests. 
Now, when you start developing a task from Jira (development task), you will split it into smaller chunks (we call them development steps) that are actionable items you would set out to implement into the codebase. Each development step can be one of the following:

Command run ‚Äì a command that needs to be run on the machine, such as a command to install a dependency, start the app to check if the previously implemented steps work, or create a folder.
Code change ‚Äì the most important development step that explains what exactly needs to be implemented in the actual code to fulfill the current step. It can contain new code that needs to be written or code that needs to be changed. The way it works is the code change is a detailed, human-readable description of what needs to be implemented. It contains both the code that needs to be implemented and the description of what it is being used for. This is very similar to when you ask ChatGPT to code something. It will give you the code as well as the explanations of why it wrote that code.
The reason for this is that code implementation is not so simple. Sometimes, we need to add a snippet into existing code or change the existing implementation. That is why we separated the outline of the coding change (this development task) and the actual implementation of this change that the CodeMonkey agent is dedicated to. I will go deeper into that in the #3 Coding section. Here is an example of a code change:
Human intervention ‚Äì a development step that AI cannot do by itself and needs human help in fulfilling the step. Then, GPT Pilot asks the developer to do something, and when he/she is done, they write ‚Äúcontinue,‚Äù and GPT Pilot will continue with the implementation. Here are some reasons why human intervention might be needed:
There is a needed API key (e.g., Twitter API key to fetch data from Twitter)
GPT Pilot became stuck in a debugging process, and it either filled the entire context length or the recursion conversation was too deep and became unproductive to continue down the recursion depth.
GPT Pilot needs a verification if something works as expected ‚Äì e.g., GPT Pilot is not sure if Mongo is installed properly on the machine and might ask the developer to run some sudo commands and see if it works as expected.

## 2 Fetching of currently implemented code
It‚Äôs easy for AI to write a new file that contains code, but in reality, that is rarely the case. For the most part, we write into the existing files and either change the existing code or add new code. Now, AI can do this easily if you give it all of the existing code and instructions for what needs to be implemented. The problem arises when an app scales and the codebase becomes so large that it cannot fit into the LLM context. And this is actually a very common case ‚Äì at least until we have LLMs with 1M tokens, which doesn‚Äôt seem to be coming soon.

When you work on a task in a big codebase, you usually look at a smaller part of the codebase (maybe 1,000 lines) and work only with that subset of code to implement the task.

So, to address this issue and make GPT Pilot truly scalable so that it can create and upgrade large production-ready codebases, we must create a way for the AI to select the smaller part of the codebase (e.g., those 1,000 lines) on which it will implement the current task. Once it‚Äôs finished, we can simply add the finished lines back into the original codebase.Let me start explaining this by telling you what happens when GPT Pilot writes code and creates new files and folders. For each file and folder it must create, it needs to write a description of what the idea is behind the file or folder it wants to create. For example, it might want to create a folder utils for which it will write:

1
2
3
Contains utility modules that provide generic, reusable solutions to common problems encountered throughout the application.
These utilities are not specific to the app's core domain but offer auxiliary functionality to support and streamline the primary codebase.
They encapsulate best practices, reduce code repetition, and make the overall code cleaner and easier to maintain. Examples include functions for data formatting, error handling, debugging tools, string manipulation, data validation, and other shared operations that don't fit within specific modules or components of the app.
Now, for each function GPT Pilot creates, it writes a description of what the function is supposed to do ‚Äì that is a pseudocode for the entire codebase.

Now that you know what happens when GPT Pilot writes code, you can understand how it fetches the relevant code for each development step.

Before GPT Pilot codes each step, it first fetches the relevant part of the codebase in a completely separate LLM conversation. That conversation is set up in 3 steps.

AI is given the development step description along with the entire project file/folder structure and descriptions for each file and folder. From this, LLM tells us which files are relevant for the mentioned step.
After narrowing down the necessary files, we give the LLM pseudocode for each file it listed and ask it to tell us which functions are relevant for the current development step.
Once we know the pseudocode it selected, we can fetch the actual code and put it into the original conversation, where the LLM will write the description of what needs to be implemented.
If the app becomes extremely huge, we can improve this by first giving the LLM the folders, from which it will select folders, and then we give it relevant files. Before each of these steps, we can also rewind the conversation to the beginning to leave more room in the context.

Here is a diagram of what this looks like:

![gpt-pilot-copy-of-gpt-pilot-selecting-code-for-llm](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/a15f4d48-bfd8-483f-b852-6a633ff3579f)


## 3 Coding
Now that we can create an LLM message that contains all code necessary for someone to implement a specific task, we can start with the actual coding process. This happens in a 2-part process:

First, the LLM writes the description of what needs to be implemented along with the code. If the entire file needs to be coded, LLM‚Äôs response will contain all the code, but if only a part of the code inside a file needs to be changed, LLM will tell us things like After the Mongo setup, add the following lines of code‚Ä¶ As you can imagine, by this being stochastic rather than deterministic, we need to ensure that the written code is inserted into appropriate places or changed correctly.
Here is where the CodeMonkey agent steps in. It is called code monkey because it doesn‚Äôt make any decisions but rather simply implements the code that the Developer agent writes. It is given the code relevant for the current task (that is previously selected by LLM in the code-fetching phase) and the description that the Developer agent created in development step #1. Then, the only thing it needs to return are the completely coded sections/files that we can just insert/replace in the codebase.

## 4 Testing
There are 2 places where testing is done ‚Äì (1) after each development task when GPT Pilot creates integration tests that test if the high-level features work as intended and (2) after each development step when it creates smaller unit tests that ensure all functions work as expected.

GPT Pilot has 3 different types of test it can do:

Automated tests are the preferred way of testing a step or task because they will be used in a regression test suite so that GPT Pilot can be sure that new code changes don‚Äôt break old features. However, automated tests are not always the most optimal way to test new code.
Command run is a test where we run a specific command and give the output to the LLM, which then tells us if the implementation was successful. For example, we don‚Äôt need to create an automated test that will check if we can run an app with npm run start ‚Äì for that, a simple command run is enough to check if we successfully set up our environment.
Human intervention is the final way to test the app, and it is needed whenever AI cannot test the implementation itself. This is needed, for example, when there are some visual aspects (e.g., CSS animations) that must be checked to see if they work correctly.
After running each test, if successful, GPT Pilot takes on the next task or step and continues with coding, but when the test fails, GPT Pilot needs to debug the error.

## 5 Debugging
The debugging process needs to be so robust so that it can be started on any bug that arises, regardless of the error. It also needs to be able to debug any issue that happens during the debugging process. This is where recursive conversations come in, which are conversations with the LLM that are set up in a way that they can be used ‚Äúrecursively.‚Äù

Let‚Äôs look at the example in the image below. It represents a flow that GPT Pilot goes through when working on a development task that has 5 development steps. In this example, during the development of step #3, an error occurs ‚Äì let‚Äôs say it implements a specific code change but after running a test, it fails. Then, it goes into the recursion level #1 to debug this issue. It breaks down what needs to be done to fix this issue into 2 steps, but during the implementation of the first step, another error happens. For example, a needed dependency for fixing the error #1 doesn‚Äôt exist. GPT Pilot then goes into the recursion level #2, which it breaks down into 3 steps. In the third step, another error occurs. Then, it goes to the third recursion level, which has only 1 step. Once that step is successfully executed, GPT Pilot goes back to the recursion level #2 and finishes debugging error #2. After that, it goes back to debugging error #1, and finally, after error #1 is fixed, it goes back to the development step #3 after which it continues the app implementation.

![gpt-pilot-frame-1-1](https://github.com/wyysfzj/Coursera-ML-AndrewNg-Notes/assets/16334545/702080f2-fd3a-4c44-8abd-2f8e5d6833f1)


When the recursions go 5 levels deep, GPT Pilot will stop the debugging process and ask the developer to fix the initial issue it started with. Once the developer resolves this issue, they write the results to GPT Pilot. Then, it can continue the development process as if it debugged the issue itself.

Conclusion
In the first post of this series, I discussed the high-level overview of how GPT Pilot works. In this post, I described the GPT Pilot Coding Workflow, including:

How Developer and CodeMonkey agents work together to implement code (write new files or update existing ones),
How recursive conversations and context rewinding work in practice, and
Rewinding the app development process and restoring it from any development step.
In the final post, I will dive deep into how all the agents are structured. We built the agents modularly because we know they will evolve over time.Please head over to GitHub, clone the GPT Pilot repository, experiment with it, and send me your feedback. I want GPT Pilot to be as helpful to developers as possible, so let me know what you think, how it can be improved, or what works well. Add comments at the bottom this post or email me at zvonimir@pythagora.ai. And while you‚Äôre at it, please star our repo so that we can spread the word.


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

